# Global Defaults
seed: 42
device: "cuda"

# LLM Configuration
llm:
  provider: "ollama"  # Options: "ollama", "mock"
  model: "llama3"
  base_url: "http://localhost:11434"

# Startup Configuration
healthcheck_on_startup: true

# Dataset Configuration
dataset: "metaqa"
output_dir: "runs/"

# Experiment Metadata
experiment_name: "default_experiment"
description: "Base configuration"

# Model Configs
llm:
  provider: "mock" # or "ollama"
  model: "llama3"
  
retrieval:
  k: 5
  type: "hybrid" # vector, graph, hybrid
  
agent:
  max_hops: 3
  max_expansions: 5
